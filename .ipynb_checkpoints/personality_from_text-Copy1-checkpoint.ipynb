{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup\n",
    "We start off by importing the Python libraries we need. We also import the `essays` dataset (`essays.csv`) that we can find in the `data` directory of our project. We also format the column names, so that they are easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authid</th>\n",
       "      <th>text</th>\n",
       "      <th>ext</th>\n",
       "      <th>neu</th>\n",
       "      <th>agr</th>\n",
       "      <th>con</th>\n",
       "      <th>opn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authid                                               text ext neu  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...   n   y   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...   n   n   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...   n   y   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...   y   n   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...   y   n   \n",
       "\n",
       "  agr con opn  \n",
       "0   y   n   y  \n",
       "1   y   n   n  \n",
       "2   n   y   y  \n",
       "3   y   y   n  \n",
       "4   y   n   y  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import re\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "essays_raw = pd.read_csv('data/essays.csv', engine = 'python');\n",
    "\n",
    "def clean_colnames(df):\n",
    "    df.columns = df.columns.str.replace(\"c|#\", \"\").str.lower()\n",
    "    return df\n",
    "    \n",
    "essays = clean_colnames(essays_raw.copy())\n",
    "essays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inpect the data\n",
    "\n",
    "Let's take a quick look at the structure of the `essays` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows and columns: (2467, 7) \n",
      "\n",
      "All author ids are unique!\n",
      "\n",
      "Number of missing values per column:\n",
      "authid    0\n",
      "text      0\n",
      "ext       0\n",
      "neu       0\n",
      "agr       0\n",
      "con       0\n",
      "opn       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authid</th>\n",
       "      <th>text</th>\n",
       "      <th>ext</th>\n",
       "      <th>neu</th>\n",
       "      <th>agr</th>\n",
       "      <th>con</th>\n",
       "      <th>opn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authid                                               text ext neu  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...   n   y   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...   n   n   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...   n   y   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...   y   n   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...   y   n   \n",
       "\n",
       "  agr con opn  \n",
       "0   y   n   y  \n",
       "1   y   n   n  \n",
       "2   n   y   y  \n",
       "3   y   y   n  \n",
       "4   y   n   y  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the number of rows and colums\n",
    "print(\"\\nNumber of rows and columns: {} \\n\".format(essays.shape))\n",
    "\n",
    "# Check if author ids are unique\n",
    "if essays.authid.value_counts().max() == 1:\n",
    "    print('All author ids are unique!\\n')\n",
    "else:\n",
    "    print('Author ids are not unique!\\n')\n",
    "    \n",
    "# Check if there are missing values in the dataset:\n",
    "print(\"Number of missing values per column:\\n{}\". format(essays.isnull().sum()))\n",
    "\n",
    "# Print the first few rows of the dataset\n",
    "essays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a datasset containing 2467 essays from the same number of individual students (Agarwal, 2014). We can also see that the dataset does not contain any missing values. Each essay is associated with an author id and 5 binary labels (one label per personality dimension):\n",
    "\n",
    "* Extraversion (`ext`)\n",
    "* Neuroticism (`neu`)\n",
    "* Agreeableness (`agr`)\n",
    "* Conscientiousness (`con`)\n",
    "* Openess (`opn`)\n",
    "\n",
    "Note that in psychological theory, the Big Five model actually considers all five traits as independent continious dimensions (and even defines sub dimensions - so-called facets - for each of them). However, for this machine learning task, the labels in our datasets represent just binary categories (e.g. a value of `y` in the `neu`-column indicates that the author of the given essay is neurotic). For more information on the Big Five personality theory see Costa and McCrae (1995).\n",
    "\n",
    "Obviously, our goal is to predict the five binary labels for a given essay. In the other words, the task at hand is a binary multi label classification task. Before we create a train-test split and preprocess our data, let's explore it a little bit further. For example we can look at the distribution of labels for each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>dimension</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>ext</td>\n",
       "      <td>1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>y</td>\n",
       "      <td>ext</td>\n",
       "      <td>1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>neu</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>y</td>\n",
       "      <td>neu</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>n</td>\n",
       "      <td>agr</td>\n",
       "      <td>1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>y</td>\n",
       "      <td>agr</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>n</td>\n",
       "      <td>con</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>y</td>\n",
       "      <td>con</td>\n",
       "      <td>1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>n</td>\n",
       "      <td>opn</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>y</td>\n",
       "      <td>opn</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label dimension  count\n",
       "0     n       ext   1191\n",
       "1     y       ext   1276\n",
       "2     n       neu   1234\n",
       "3     y       neu   1233\n",
       "4     n       agr   1157\n",
       "5     y       agr   1310\n",
       "6     n       con   1214\n",
       "7     y       con   1253\n",
       "8     n       opn   1196\n",
       "9     y       opn   1271"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = pd.melt(essays.iloc[:, 2:7].apply(pd.Series.value_counts).reset_index().copy(),\n",
    "                       id_vars = ['index'], var_name = 'dimension', value_name = 'count').rename(columns = {'index': 'label'})\n",
    "\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27db1a3b508>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = \"dimension\", y = \"count\", hue = \"label\", data = label_counts)\n",
    "plt.legend(loc = 'center right')\n",
    "plt.legend(bbox_to_anchor = (1.05, 1), loc = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot we can see that for each dimension the number of samples on the positive class (`y`) is roughly equal to the number of samples of the negative class (`n`). In other words, our dataset is appears to be pretty balanced (at least, if you look at each dimension separatly) Let's also look at the counts of individual combinations of dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indiv_combs = (essays['ext'] + essays['neu'] + essays['agr'] + essays['con'] + essays['opn']). \\\n",
    "               value_counts()\n",
    "\n",
    "indiv_combs.plot(kind = \"bar\", color = \"lightblue\")\n",
    "len(indiv_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above we can see that the individual combinations of dimensions are not equally frequent. Depending on how we attempt to solve our classification problem later on, this is something we want to keep in mind.\n",
    "\n",
    "As another exploration step, let's take a look at the number of characters in the `text`-column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "char_counts = essays.text.str.len()\n",
    "\n",
    "print(char_counts.hist(bins = int(np.sqrt(len(essays)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most essays appear to be between 2000 and 4000 characters long. There appear to be some outliers as well (e.g. some essays with a relatively high character count). This is something we want to keep in mind for later, as well.\n",
    "\n",
    "Also, we should look at some sample essays to see which kind of preprocessing we should do later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, right now I just woke up from a mid-day nap. It\\'s sort of weird, but ever since I moved to Texas, I have had problems concentrating on things. I remember starting my homework in  10th grade as soon as the clock struck 4 and not stopping until it was done. Of course it was easier, but I still did it. But when I moved here, the homework got a little more challenging and there was a lot more busy work, and so I decided not to spend hours doing it, and just getting by. But the thing was that I always paid attention in class and just plain out knew the stuff, and now that I look back, if I had really worked hard and stayed on track the last two years without getting  lazy, I would have been a genius, but hey, that\\'s all good. It\\'s too late to correct the past, but I don\\'t really know how to stay focused n the future. The one thing I know is that when  people say that b/c they live on campus they can\\'t concentrate, it\\'s b. s. For me it would be easier there, but alas, I\\'m living at home under the watchful eye of my parents and a little nagging sister that just nags and nags and nags. You get my point. Another thing is, is that it\\'s just a hassle to have to go all the way back to  school to just to go to library to study. I need to move out, but I don\\'t know how to tell them. Don\\'t get me wrong, I see where they\\'re coming from and why they don\\'t  want me to move out, but I need to get away and be on my own. They\\'ve sheltered me so much and I don\\'t have a worry in the world. The only thing that they ask me to do is keep my room clean and help out with the business once in a while, but I can\\'t even do that. But I need to. But I got enough money from UT to live at a dorm or apartment  next semester and I think I’ll take advantage of that. But off that topic now, I went to sixth street last night and had a blast. I haven\\'t been there in so long. Now I know why I love Austin so much. When I lived in VA, I used to go up to DC all the time and had a blast, but here, there are so many students running around at night. I just want to have some fun and I know that I am responsible enough to be able to  have fun, but keep my priorities straight. Living at home, I can\\'t go out at all without them asking where? with who?  why?  when are you coming back?  and all those  questions. I just wish I could be treated like a responsible person for once, but  my sister screwed that up for me. She went crazy the second she moved into college and messed up her whole college career by partying too much. And that\\'s the ultimate reason that they don\\'t want me to go and have fun. But I\\'m not little anymore,  and they need to let me go and explore the world, but I’m Indian; with Indian culture, with Indian values. They go against \"having fun. \"  I mean in the sense of meeting people or going out with people or partying or just plain having fun. My school is difficult already, but somehow I think that having more freedom will put more pressure on me to  do better in school b/c that\\'s what my parents and ultimately I expect of myself. Well it\\'s been fun writing, I don\\'t know if you go anything out of this writing, but it helped me get some of my thoughts into order. So I hope you had fun reading it and good luck TA\\'s.    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text looks pretty messy: For example, there are a lot of special characters and abbreviations. This is not optimal if you want to feed the text to a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing\n",
    "\n",
    "In this part, we will create classes that allow us clean our dataset. The goal is to have a nice and clean dataset that we can feed into a machine learning model.\n",
    "\n",
    "Note that we define a class for each preprocessing step, so that we can build a pipeline that combines all steps later on. We implement these classes as *transformer classes* to be able to feed them into pipelines. While `sklearn`comes with a lot of useful *transformer classes* already, we implement most classes we need by hand to get some practice.\n",
    "\n",
    "We also test each class on a copy of the dataset to make sure that the classes work as expected.\n",
    "\n",
    "## 3.1 Define preprocessing functions\n",
    "First, a class that cleans the column names of the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authid</th>\n",
       "      <th>text</th>\n",
       "      <th>ext</th>\n",
       "      <th>neu</th>\n",
       "      <th>agr</th>\n",
       "      <th>con</th>\n",
       "      <th>opn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authid                                               text ext neu  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...   n   y   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...   n   n   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...   n   y   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...   y   n   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...   y   n   \n",
       "\n",
       "  agr con opn  \n",
       "0   y   n   y  \n",
       "1   y   n   n  \n",
       "2   n   y   y  \n",
       "3   y   y   n  \n",
       "4   y   n   y  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ColNameCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X.columns = X.columns.str.replace(\"c|#\", \"\").str.lower()\n",
    "        return X\n",
    "\n",
    "cleaner = ColNameCleaner()\n",
    "cleaner.transform(essays_raw.copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement a class that drops the `#AUTHID` / `authid` column because we actually do not need it for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT cEXT cNEU cAGR cCON cOPN\n",
       "0  Well, right now I just woke up from a mid-day ...    n    y    y    n    y\n",
       "1  Well, here we go with the stream of consciousn...    n    n    y    n    n\n",
       "2  An open keyboard and buttons to push. The thin...    n    y    n    y    y\n",
       "3  I can't believe it!  It's really happening!  M...    y    n    y    y    n\n",
       "4  Well, here I go with the good old stream of co...    y    n    y    n    y"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.drop(columns = self.column)\n",
    "        return X\n",
    "    \n",
    "dropper = ColDropper(column = \"#AUTHID\")\n",
    "dropper.transform(essays_raw.copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"For good measure\", we also implement a class that converts the `y` labels to `True` on the `n` labels to `False` for each personality dimension. Note that in order to use this class the column names need to be cleaned up already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authid</th>\n",
       "      <th>text</th>\n",
       "      <th>ext</th>\n",
       "      <th>neu</th>\n",
       "      <th>agr</th>\n",
       "      <th>con</th>\n",
       "      <th>opn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authid                                               text    ext  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...  False   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...  False   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...  False   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...   True   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...   True   \n",
       "\n",
       "     neu    agr    con    opn  \n",
       "0   True   True  False   True  \n",
       "1  False   True  False  False  \n",
       "2   True  False   True   True  \n",
       "3  False   True   True  False  \n",
       "4  False   True  False   True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LabelTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['ext'], X['neu'], X['agr'], X['con'], X['opn'] = [[True if x == 'y' else False for x in col] \\\n",
    "                                                                                         for col in [X['ext'],\n",
    "                                                                                                     X['neu'],\n",
    "                                                                                                     X['agr'],\n",
    "                                                                                                     X['con'], \n",
    "                                                                                                     X['opn']]]\n",
    "        return X\n",
    "    \n",
    "lbl_trnsfr = LabelTransformer()\n",
    "lbl_trnsfr.transform(essays.copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output above, the string labels got turned into boolean values (True, False).\n",
    "\n",
    "Next, we create a function to clean the `TEXT` /`text` column. This function turns all letters to lower case and removes some abbreviations that are common in the english language. It also removes special characters and multiple consecutive spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well right now i just woke up from a mid day nap it sort of weird but ever since i moved to texas i have had problems concentrating on things i remember starting my homework in 10th grade as soon as the clock struck 4 and not stopping until it was done of course it was easier but i still did it but when i moved here the homework got a little more challenging and there was a lot more busy work and so i decided not to spend hours doing it and just getting by but the thing was that i always paid attention in class and just plain out knew the stuff and now that i look back if i had really worked hard and stayed on track the last two years without getting lazy i would have been a genius but hey that all good it too late to correct the past but i do not really know how to stay focused n the future the one thing i know is that when people say that because they live on campus they can not concentrate it b s for me it would be easier there but alas i am living at home under the watchful eye of my parents and a little nagging sister that just nags and nags and nags you get my point another thing is is that it just a hassle to have to go all the way back to school to just to go to library to study i need to move out but i do not know how to tell them do not get me wrong i see where they are coming from and why they do not want me to move out but i need to get away and be on my own they have sheltered me so much and i do not have a worry in the world the only thing that they ask me to do is keep my room clean and help out with the business once in a while but i can not even do that but i need to but i got enough money from ut to live at a dorm or apartment next semester and i think i will take advantage of that but off that topic now i went to sixth street last night and had a blast i have not been there in so long now i know why i love austin so much when i lived in va i used to go up to dc all the time and had a blast but here there are so many students running around at night i just want to have some fun and i know that i am responsible enough to be able to have fun but keep my priorities straight living at home i can not go out at all without them asking where with who why when are you coming back and all those questions i just wish i could be treated like a responsible person for once but my sister screwed that up for me she went crazy the second she moved into college and messed up her whole college career by partying too much and that the ultimate reason that they do not want me to go and have fun but i am not little anymore and they need to let me go and explore the world but i am indian with indian culture with indian values they go against having fun i mean in the sense of meeting people or going out with people or partying or just plain having fun my school is difficult already but somehow i think that having more freedom will put more pressure on me to do better in school because that what my parents and ultimately i expect of myself well it been fun writing i do not know if you go anything out of this writing but it helped me get some of my thoughts into order so i hope you had fun reading it and good luck ta'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"i’m\", \"i am \", text)\n",
    "    text = re.sub('b/c', 'because', text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"’ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "clean_text(essays_raw.TEXT[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we take a look at our sample essay now, it looks pretty good. Note that to make things simpler a string like `it's` is striped down to just `it`. We chose to do so because `is` is a typical stopword that we'll remove anyway.\n",
    "\n",
    "Now, we implement a class `TextCleaner` that applies the `clean_text` function to every row in the  `TEXT` / `text` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>well right now i just woke up from a mid day n...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>well here we go with the stream of consciousne...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>an open keyboard and buttons to push the thing...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>i can not believe it it really happening my pu...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>well here i go with the good old stream of con...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT cEXT  \\\n",
       "0  1997_504851.txt  well right now i just woke up from a mid day n...    n   \n",
       "1  1997_605191.txt  well here we go with the stream of consciousne...    n   \n",
       "2  1997_687252.txt  an open keyboard and buttons to push the thing...    n   \n",
       "3  1997_568848.txt  i can not believe it it really happening my pu...    y   \n",
       "4  1997_688160.txt  well here i go with the good old stream of con...    y   \n",
       "\n",
       "  cNEU cAGR cCON cOPN  \n",
       "0    y    y    n    y  \n",
       "1    n    y    n    n  \n",
       "2    y    n    y    y  \n",
       "3    n    y    y    n  \n",
       "4    n    y    n    y  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline test\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.column] = X[self.column].apply(clean_text)\n",
    "        return X\n",
    "\n",
    "cleaner = TextCleaner(\"TEXT\")\n",
    "cleaner.transform(essays_raw.copy()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks alright. Our preprocessing classes seem to work fine. It's time to build a pipeline that combines the different preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Build and apply cleaning pipeline\n",
    "\n",
    "We create a pipelines that contain the preprocessing steps we defined earlier. We can pass the raw data to the apply to create a clean data set that is (almost) ready to be fed to an machine learning algorithm.\n",
    "\n",
    "In fact, we will create a first pipeline that applies all the steps we defined earlier. A second pipeline will be applied after the train-test-split and will use the class `TfidfVectorizer` from `sklearn` to tokenize the text data and compute tf-idf statistics. This class can also be used to remove stop words from text input. Stop words are words that occur very frequently and thus do not contain much information about the specific content of a text. This pipeline will also contain the model step (i.e. fitting a random forrest).\n",
    "\n",
    "This seperation into two pipelines is neccessary because  `TfidfVectorizer` alters the shape of the input data. Thus, in order to feed datasets of different sizes (i.e. the test set or new data in general) into a trained model, tokenization should go hand in hand with the modelling step. A disadvantage of this approach is that everytime we fit a model, the  tokenization step needs to be executed as well which takes more time compared to just fitting the model.\n",
    "\n",
    "Building the first pipeline that applies all the cleaning steps except tokenization of the text column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ext</th>\n",
       "      <th>neu</th>\n",
       "      <th>agr</th>\n",
       "      <th>con</th>\n",
       "      <th>opn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>well right now i just woke up from a mid day n...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>well here we go with the stream of consciousne...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>an open keyboard and buttons to push the thing...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i can not believe it it really happening my pu...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>well here i go with the good old stream of con...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    ext    neu    agr  \\\n",
       "0  well right now i just woke up from a mid day n...  False   True   True   \n",
       "1  well here we go with the stream of consciousne...  False  False   True   \n",
       "2  an open keyboard and buttons to push the thing...  False   True  False   \n",
       "3  i can not believe it it really happening my pu...   True  False   True   \n",
       "4  well here i go with the good old stream of con...   True  False   True   \n",
       "\n",
       "     con    opn  \n",
       "0  False   True  \n",
       "1  False  False  \n",
       "2   True   True  \n",
       "3   True  False  \n",
       "4  False   True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pipeline = Pipeline([('colclean', ColNameCleaner()),\n",
    "                           ('idcoldrop', ColDropper(\"authid\")),\n",
    "                           ('lbltransf', LabelTransformer()),\n",
    "                           ('txtclean', TextCleaner(\"text\"))])\n",
    "\n",
    "essays_clean = clean_pipeline.transform(essays_raw.copy())\n",
    "essays_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Create a training set and a testing set\n",
    "\n",
    "We create a train test split from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1726,)\n",
      "(741,)\n",
      "(1726, 5)\n",
      "(741, 5)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(essays_clean, random_state = 42, test_size = 0.3, shuffle = True)\n",
    "\n",
    "X_train = train['text'].copy()\n",
    "Y_train = train.copy().drop('text', axis = 1)\n",
    "\n",
    "X_test = test['text'].copy()\n",
    "Y_test = test.copy().drop('text', axis = 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explore models\n",
    "\n",
    "In the next step we try out some common machine learning algorithms on the preprocessed training set and see which algorithms appear to be promising. We also choose the approach to fit a separate model for each label as done by previous work (e.g. Majumder et al., 2017). We write a function that applies a modelling pipleine (computing tf-idf statistics for the `text` column and fittting seperate model for each personality dimension). The function also evalutes the model on the training set using the `accuracy` metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_clf(classifier, categories = ['ext', 'neu', 'agr', 'con', 'opn']):\n",
    "    \n",
    "    # Define the modelling pipeline in the function so that the function is self-contained\n",
    "    model_pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words = stop_words)),\n",
    "                               ('clf', classifier)])\n",
    "    \n",
    "    print('Accuracy using {}'.format(classifier))\n",
    "    \n",
    "    for category in categories:\n",
    "        print(\"Fitting model for {}...\".format(category))\n",
    "        \n",
    "        model_pipeline.fit(X_train, Y_train[category])\n",
    "        preds = model_pipeline.predict(X_train)\n",
    "        \n",
    "        print('Dimension {}: {}'.format(category, accuracy_score(Y_train[category], preds)))\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can easily apply this function to some algorithms we are interested in. By the way, as an alternative approach we could have used `sklearn`'s `MultiOuputClassifier` class to handle multi label classification (some algorithms support it by default, e.g. `KNeighborsClassifier`).\n",
    "\n",
    "Exmaple of training a classifier using the `MultiOutputClassifier`class:\n",
    "\n",
    "`forest_clf = MultiOutputClassifier(RandomForestClassifier(n_estimators = 20))`\n",
    "\n",
    "`forest_clf.fit(X_train_prepared, y_train_prepared)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Fitting model for ext...\n",
      "Dimension ext: 0.8644264194669756\n",
      "Fitting model for neu...\n",
      "Dimension neu: 0.9623406720741599\n",
      "Fitting model for agr...\n",
      "Dimension agr: 0.6761297798377752\n",
      "Fitting model for con...\n",
      "Dimension con: 0.921784472769409\n",
      "Fitting model for opn...\n",
      "Dimension opn: 0.9258400926998841\n",
      "\n",
      "\n",
      "Accuracy using RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Fitting model for ext...\n",
      "Dimension ext: 1.0\n",
      "Fitting model for neu...\n",
      "Dimension neu: 1.0\n",
      "Fitting model for agr...\n",
      "Dimension agr: 1.0\n",
      "Fitting model for con...\n",
      "Dimension con: 1.0\n",
      "Fitting model for opn...\n",
      "Dimension opn: 1.0\n",
      "\n",
      "\n",
      "Accuracy using LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Fitting model for ext...\n",
      "Dimension ext: 0.9333719582850522\n",
      "Fitting model for neu...\n",
      "Dimension neu: 0.9391657010428737\n",
      "Fitting model for agr...\n",
      "Dimension agr: 0.9125144843568945\n",
      "Fitting model for con...\n",
      "Dimension con: 0.936268829663963\n",
      "Fitting model for opn...\n",
      "Dimension opn: 0.8736964078794901\n",
      "\n",
      "\n",
      "Accuracy using XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=0.5, verbosity=1)\n",
      "Fitting model for ext...\n",
      "Dimension ext: 1.0\n",
      "Fitting model for neu...\n",
      "Dimension neu: 1.0\n",
      "Fitting model for agr...\n",
      "Dimension agr: 1.0\n",
      "Fitting model for con...\n",
      "Dimension con: 1.0\n",
      "Fitting model for opn...\n",
      "Dimension opn: 1.0\n",
      "\n",
      "\n",
      "None None None None\n"
     ]
    }
   ],
   "source": [
    "classifiers = [MultinomialNB(fit_prior = True, class_prior = None),\n",
    "               RandomForestClassifier(n_estimators = 50),\n",
    "               LogisticRegression(solver = 'sag'),\n",
    "               xgb.XGBClassifier(n_estimators = 100, max_depth = 8, learning_rate = 0.1, subsample = 0.5)]\n",
    "\n",
    "nb_clf, forest_clf, log_clf, xgb_clf = list((map(multi_label_clf, classifiers)))\n",
    "print(nb_clf, forest_clf, log_clf, xgb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model tuning\n",
    "The RandomForrestClassifer seems to do very well (perfect accuracy for all dimensions). The logistic regression and the classifier using extreme gradient boosting perform good as well. So, we further explore these two model types.\n",
    "\n",
    "The perfect accuracy of the random forest model (accuracy scores of 1.0 for all five dimensions) indicates that the random forrest algorithm overfits the data. We don't want to touch our test set yet since we still need to fine-tune our model. To get a more realistic estimate on how the models perform on new data we can use cross-validation.\n",
    "\n",
    "(As we waw in our data exploration, the dataset is quite balanced so looking at the accuracy to evaluate the model should be okay. Of course, it is no mistake to look at other metrics as well - for example precision, recall and the F1-score.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_clf_cv(classifier, categories = ['ext', 'neu', 'agr', 'con', 'opn']):\n",
    "    \n",
    "    # Define the modelling pipeline in the function so that the function is self-contained\n",
    "    model_pipeline = Pipeline([ ('tfidf', TfidfVectorizer(stop_words = stop_words)),\n",
    "                               ('clf', classifier)])\n",
    "    \n",
    "    print('Accuracy using {}'.format(classifier))\n",
    "    \n",
    "    for category in categories:\n",
    "        print(\"Fitting model for {}...\".format(category))\n",
    "        \n",
    "        model_pipeline.fit(X_train, Y_train[category])\n",
    "        scores = cross_val_score(model_pipeline, X_train, Y_train[category], scoring = \"accuracy\", cv = 3)\n",
    "        \n",
    "        print('Cross validation accuracy for dimension {}: {}'.format(category, scores))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Fitting model for ext...\n",
      "Cross validation accuracy for dimension ext: [0.56076389 0.52777778 0.52090592]\n",
      "Fitting model for neu...\n",
      "Cross validation accuracy for dimension neu: [0.5        0.5426087  0.49391304]\n",
      "Fitting model for agr...\n",
      "Cross validation accuracy for dimension agr: [0.5        0.52173913 0.52173913]\n",
      "Fitting model for con...\n",
      "Cross validation accuracy for dimension con: [0.51215278 0.55555556 0.53832753]\n",
      "Fitting model for opn...\n",
      "Cross validation accuracy for dimension opn: [0.59201389 0.54340278 0.55749129]\n",
      "\n",
      "\n",
      "Accuracy using LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Fitting model for ext...\n",
      "Cross validation accuracy for dimension ext: [0.55381944 0.56076389 0.57317073]\n",
      "Fitting model for neu...\n",
      "Cross validation accuracy for dimension neu: [0.55034722 0.55652174 0.57043478]\n",
      "Fitting model for agr...\n",
      "Cross validation accuracy for dimension agr: [0.53125    0.54608696 0.55478261]\n",
      "Fitting model for con...\n",
      "Cross validation accuracy for dimension con: [0.57465278 0.578125   0.57491289]\n",
      "Fitting model for opn...\n",
      "Cross validation accuracy for dimension opn: [0.60243056 0.61284722 0.6184669 ]\n",
      "\n",
      "\n",
      "Accuracy using XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=30, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting model for ext...\n",
      "Cross validation accuracy for dimension ext: [0.50868056 0.52951389 0.53310105]\n",
      "Fitting model for neu...\n",
      "Cross validation accuracy for dimension neu: [0.53819444 0.51478261 0.54608696]\n",
      "Fitting model for agr...\n",
      "Cross validation accuracy for dimension agr: [0.50173611 0.52869565 0.53913043]\n",
      "Fitting model for con...\n",
      "Cross validation accuracy for dimension con: [0.52951389 0.52083333 0.5       ]\n",
      "Fitting model for opn...\n",
      "Cross validation accuracy for dimension opn: [0.59027778 0.61111111 0.55923345]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_label_clf_cv(RandomForestClassifier(n_estimators = 50, random_state = 42))\n",
    "multi_label_clf_cv(LogisticRegression(solver = 'sag'))\n",
    "multi_label_clf_cv(xgb.XGBClassifier(n_estimators = 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oof! When using cross validation the algorithms do not do as well as expected. The accuracy for most dimensions is barely above chance level (50%). Now, the logistic regression seems to do a little bit better compared the random forest. One thing we can do to optimize our model is tune its hyperparameters using grid search or randomized search.\n",
    "\n",
    "`LogisticRegression` shows the best results out of the models we tried. So we'll focus our hyperparameter tuning on this on type of model.\n",
    "\n",
    "Remember that we actually fit one model per personality dimension. We will do a grid search for each model (per dimension) to find good hyperparameters. We'll only focus on some of the possbile hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform for each model\n",
    "def log_reg_search(category):\n",
    "    log_reg_pipe = Pipeline([(\"tfidf\",  TfidfVectorizer(stop_words = stop_words)),\n",
    "                             ('clf', LogisticRegression())])\n",
    "\n",
    "    param_grid = {\"clf__C\": np.logspace(-3, 3, 7),\n",
    "                  \"clf__penalty\": [\"l1\", \"l2\"]\n",
    "                 }\n",
    "\n",
    "    grid_search = GridSearchCV(log_reg_pipe, param_grid, cv = 3,\n",
    "                              scoring = 'accuracy')\n",
    "\n",
    "    grid_search.fit(X_train, Y_train[category])\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell might take a few minutes\n",
    "categories = ['ext', 'neu', 'agr', 'con', 'opn']\n",
    "\n",
    "best_ext_model, best_neu_model, best_agr_model,best_con_model, best_opn_model = list(map(log_reg_search, categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have extracted the best model for each dimension. Note that all models also include the tokenization step, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all'...\n",
       "                                 strip_accents=None, sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ext_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracy scores for dimension ext: [0.56076389 0.55208333 0.58013937]\n",
      "Cross validation accuracy scores for dimension neu: [0.56423611 0.55304348 0.58956522]\n",
      "Cross validation accuracy scores for dimension agr: [0.53125    0.54608696 0.55652174]\n",
      "Cross validation accuracy scores for dimension con: [0.55555556 0.58680556 0.58885017]\n",
      "Cross validation accuracy scores for dimension opn: [0.60416667 0.609375   0.62020906]\n"
     ]
    }
   ],
   "source": [
    "models = [best_ext_model, best_neu_model, best_agr_model,best_con_model, best_opn_model]\n",
    "categories = ['ext', 'neu', 'agr', 'con', 'opn']\n",
    "\n",
    "for model, category in zip(models, categories):\n",
    "    model.fit(X_train, Y_train[category])\n",
    "    scores = cross_val_score(model, X_train, Y_train[category], scoring = \"accuracy\", cv = 3) \n",
    "    print(\"Cross validation accuracy scores for dimension {}: {}\".format(category, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the grid search did not improve our models by much. Anyway, let's finally evaluate the models using the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy scores for dimension ext: 0.5573549257759784\n",
      "Test accuracy scores for dimension neu: 0.5573549257759784\n",
      "Test accuracy scores for dimension agr: 0.5641025641025641\n",
      "Test accuracy scores for dimension con: 0.5330634278002699\n",
      "Test accuracy scores for dimension opn: 0.6180836707152496\n"
     ]
    }
   ],
   "source": [
    "for model, category in zip(models, categories):\n",
    "    preds = model.predict(X_test)\n",
    "    acc_score = accuracy_score(Y_test[category], preds)\n",
    "    print(\"Test accuracy scores for dimension {}: {}\".format(category, acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, at least all accuracy scores are above chance level. Personality detection from text is hard. Even Majumder et al. (2017) (who tried out a lot of different deep learning and shallow machine learning models on the essays dataset) reported that 4 out of 5 models (one per personality dimension) got an accuracy score less than 0.6 at best.\n",
    "\n",
    "Here ist the best accuracy score for each dimension reported by Majumder et al. (2017):\n",
    "* Extraversion: 58.09\n",
    "* Neuroticism: 59.38\n",
    "* Agreeableness: 56.71\n",
    "* Conscientiousness: 57.30\n",
    "* Openess: 62.68\n",
    "\n",
    "The scores from our basic logistic regression models are not that far away. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Possible improvements\n",
    "The idea of this project was to demonstrate a basic machine learning workflow. Of course, the models that we created can be improved! Some ideas of how the models could be improved:\n",
    "\n",
    "* experiment with different preprocessing approaches: embeddings (e.g. word2vec), considering sentiments (e.g. leaving out emotionally neutral sentences), etc.\n",
    "* explore a wider range of models (e.g. deep neural networks)\n",
    "* experiemnt with metrics and thresholds\n",
    "* (more \"efficient\" use of pipelines)\n",
    "\n",
    "However, detecting personality from text is not as easy as for example just predicting sentiments from text. A text might not contain any information about the author's personality as the author can choose to not reveal it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Feed completly new data to the model\n",
    "Just for fun, let's feed in some text from a celebrity person and see what our model says. How about a speech by Donald Trump? We chose a speech Trump held about the ongoing conflict between the United States and Iran (NBC News, 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as long as i am president of the united states iran will never be allowed to have a nuclear weapon good morning i am pleased to inform you the american people should be extremely grateful and happy no americans were harmed in last night s attack by the iranian regime we suffered no casualties all of our soldiers are safe and only minimal damage was sustained at our military bases our great american forces are prepared for anything iran appears to be standing down which is a good thing for all p...\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "trump_speech = Path('data/trump_iran_speech.txt').read_text()\n",
    "\n",
    "trump_speech_df = pd.Series(trump_speech).to_frame(name = \"text\")\n",
    "\n",
    "# Clean text\n",
    "cleaner = TextCleaner(\"text\")\n",
    "trump_speech_df = cleaner.transform(trump_speech_df)\n",
    "\n",
    "# Print out the first 500 characters of the speech\n",
    "print(\"{}...\".format(trump_speech_df[\"text\"][0][0:499]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use our models to predict Trump's personality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Donald Trump extroverted? False!\n",
      "Is Donald Trump neurotic? False!\n",
      "Is Donald Trump agreeable? False!\n",
      "Is Donald Trump conscientious? False!\n",
      "Is Donald Trump open? True!\n"
     ]
    }
   ],
   "source": [
    "def ask_the_model(dimension, model):\n",
    "    print(\"Is Donald Trump {}? {}!\".format(dimension, model.predict(trump_speech_df)[0]))\n",
    "    \n",
    "models = [best_ext_model, best_neu_model, best_agr_model, best_con_model, best_opn_model]\n",
    "dimensions = [\"extroverted\", \"neurotic\", \"agreeable\", \"conscientious\", \"open\"]\n",
    "\n",
    "for dimension, model in zip(dimensions, models):\n",
    "    ask_the_model(dimension, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. References\n",
    "* Agarwal, B. (2014). Personality detection from text: A Review. International Journal of Computer System, 1(1).\n",
    "* Costa, P. T., & McCrae, R. R. (1985). The NEO personality inventory.\n",
    "* Géron, A. (2018). Hands-on machine learning with Scikit-Learn and Tensorflow. Sebastopol, CA: O'Reilly Media.\n",
    "* Majumder, N., Poria, S., Gelbukh, A., & Cambria, E. (2017). Deep learning-based document modeling for personality detection from text. IEEE Intelligent Systems, 32(2), 74-79.\n",
    "* NBC News (2020). Read the full transcript of Trump's Iran speech. Retrieved from: https://www.nbcnews.com/politics/donald-trump/read-full-transcript-trump-s-iran-speech-n1112456\n",
    "* Li, S. (2018). Multi Label Text Classification with Scikit-Learn. Retrieved from:https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
